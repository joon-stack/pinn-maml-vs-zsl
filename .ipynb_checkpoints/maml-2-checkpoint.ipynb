{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13fab8b6-cb38-4b19-aade-f0939939bc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from maml import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f938ae82-3227-4892-b1d9-5ec5b9df34c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80274bf7-1db5-4590-a403-bfabd4e361fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Current device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e3a9ab-9d5b-49a7-9ad6-6ad5b4eab18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing MAML-PINN model\n",
      "Current device:  cuda\n",
      "cuda\n",
      "Zero shot mode is True\n",
      "Finished initialization of MAML-PINN model\n",
      "Start MAML training at iteration 0\n",
      "Validation before training Pre-Adapt(-0.884, 0.058)| Inner_loss_B: 0.8600 | Inner_loss_F: 0.1828 | Inner_loss: 8.7826 | NRMSE: 9.5073\n",
      "Validation before training Post-Adapt(-0.884, 0.058)| Inner_loss_B: 0.0537 | Inner_loss_F: 0.1426 | Inner_loss: 0.6798 | NRMSE: 0.2016\n",
      "Validation OOD before training Pre-Adapt(-0.380, 0.911) | Inner_loss_B: 0.8718 | Inner_loss_F: 0.1844 | Inner_loss: 8.9027 | NRMSE: 9.2871\n",
      "Validation OOD before training Post-Adapt(-0.380, 0.911) | Inner_loss_B: 0.0554 | Inner_loss_F: 0.1394 | Inner_loss: 0.6938 | NRMSE: 0.1991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fembem\\anaconda3\\envs\\torch-1.10.1\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\fembem\\anaconda3\\envs\\torch-1.10.1\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20 Pre-Adapt | Inner_loss_B: 0.7259 | Inner_loss_F: 0.2012 | Inner_loss: 7.4600\n",
      "Step 20 Post-Adapt | Inner_loss_B: 0.1704 | Inner_loss_F: 0.1818 | Inner_loss: 1.8859\n",
      "Validation before training Pre-Adapt(-0.884, 0.058)| Inner_loss_B: 0.6971 | Inner_loss_F: 0.1786 | Inner_loss: 7.1495 | NRMSE: 3.7478\n",
      "Validation before training Post-Adapt(-0.884, 0.058)| Inner_loss_B: 0.1538 | Inner_loss_F: 0.1622 | Inner_loss: 1.7003 | NRMSE: 0.2962\n",
      "Validation OOD before training Pre-Adapt(-0.380, 0.911) | Inner_loss_B: 0.7137 | Inner_loss_F: 0.1819 | Inner_loss: 7.3186 | NRMSE: 3.7796\n",
      "Validation OOD before training Post-Adapt(-0.380, 0.911) | Inner_loss_B: 0.1613 | Inner_loss_F: 0.1589 | Inner_loss: 1.7722 | NRMSE: 0.3033\n",
      "Step 40 Pre-Adapt | Inner_loss_B: 0.6419 | Inner_loss_F: 0.2275 | Inner_loss: 6.6466\n",
      "Step 40 Post-Adapt | Inner_loss_B: 0.1421 | Inner_loss_F: 0.2021 | Inner_loss: 1.6233\n",
      "Validation before training Pre-Adapt(-0.884, 0.058)| Inner_loss_B: 0.6477 | Inner_loss_F: 0.1745 | Inner_loss: 6.6517 | NRMSE: 3.0626\n",
      "Validation before training Post-Adapt(-0.884, 0.058)| Inner_loss_B: 0.1386 | Inner_loss_F: 0.1560 | Inner_loss: 1.5420 | NRMSE: 0.2849\n",
      "Validation OOD before training Pre-Adapt(-0.380, 0.911) | Inner_loss_B: 0.6628 | Inner_loss_F: 0.1789 | Inner_loss: 6.8067 | NRMSE: 3.0911\n",
      "Validation OOD before training Post-Adapt(-0.380, 0.911) | Inner_loss_B: 0.1409 | Inner_loss_F: 0.1542 | Inner_loss: 1.5627 | NRMSE: 0.2895\n",
      "Step 60 Pre-Adapt | Inner_loss_B: 0.5974 | Inner_loss_F: 0.2437 | Inner_loss: 6.2172\n",
      "Step 60 Post-Adapt | Inner_loss_B: 0.1165 | Inner_loss_F: 0.2164 | Inner_loss: 1.3817\n",
      "Validation before training Pre-Adapt(-0.884, 0.058)| Inner_loss_B: 0.6294 | Inner_loss_F: 0.1711 | Inner_loss: 6.4649 | NRMSE: 2.9151\n",
      "Validation before training Post-Adapt(-0.884, 0.058)| Inner_loss_B: 0.1132 | Inner_loss_F: 0.1477 | Inner_loss: 1.2795 | NRMSE: 0.2640\n",
      "Validation OOD before training Pre-Adapt(-0.380, 0.911) | Inner_loss_B: 0.6423 | Inner_loss_F: 0.1747 | Inner_loss: 6.5979 | NRMSE: 2.9162\n",
      "Validation OOD before training Post-Adapt(-0.380, 0.911) | Inner_loss_B: 0.1146 | Inner_loss_F: 0.1473 | Inner_loss: 1.2936 | NRMSE: 0.2673\n",
      "Step 80 Pre-Adapt | Inner_loss_B: 0.6459 | Inner_loss_F: 0.1897 | Inner_loss: 6.6488\n",
      "Step 80 Post-Adapt | Inner_loss_B: 0.0781 | Inner_loss_F: 0.1464 | Inner_loss: 0.9277\n",
      "Validation before training Pre-Adapt(-0.884, 0.058)| Inner_loss_B: 0.5906 | Inner_loss_F: 0.1625 | Inner_loss: 6.0684 | NRMSE: 2.5670\n",
      "Validation before training Post-Adapt(-0.884, 0.058)| Inner_loss_B: 0.0768 | Inner_loss_F: 0.1335 | Inner_loss: 0.9016 | NRMSE: 0.2255\n",
      "Validation OOD before training Pre-Adapt(-0.380, 0.911) | Inner_loss_B: 0.6025 | Inner_loss_F: 0.1691 | Inner_loss: 6.1942 | NRMSE: 2.5690\n",
      "Validation OOD before training Post-Adapt(-0.380, 0.911) | Inner_loss_B: 0.0767 | Inner_loss_F: 0.1356 | Inner_loss: 0.9027 | NRMSE: 0.2268\n",
      "Model saved\n",
      "Step 100 Pre-Adapt | Inner_loss_B: 0.6677 | Inner_loss_F: 0.1592 | Inner_loss: 6.8365\n",
      "Step 100 Post-Adapt | Inner_loss_B: 0.0555 | Inner_loss_F: 0.1199 | Inner_loss: 0.6750\n",
      "Validation before training Pre-Adapt(-0.884, 0.058)| Inner_loss_B: 0.6350 | Inner_loss_F: 0.1572 | Inner_loss: 6.5068 | NRMSE: 3.2902\n",
      "Validation before training Post-Adapt(-0.884, 0.058)| Inner_loss_B: 0.0516 | Inner_loss_F: 0.1226 | Inner_loss: 0.6385 | NRMSE: 0.1941\n",
      "Validation OOD before training Pre-Adapt(-0.380, 0.911) | Inner_loss_B: 0.6450 | Inner_loss_F: 0.1593 | Inner_loss: 6.6096 | NRMSE: 3.2648\n",
      "Validation OOD before training Post-Adapt(-0.380, 0.911) | Inner_loss_B: 0.0512 | Inner_loss_F: 0.1231 | Inner_loss: 0.6352 | NRMSE: 0.1958\n",
      "Step 120 Pre-Adapt | Inner_loss_B: 0.6062 | Inner_loss_F: 0.1838 | Inner_loss: 6.2462\n",
      "Step 120 Post-Adapt | Inner_loss_B: 0.0117 | Inner_loss_F: 0.1618 | Inner_loss: 0.2789\n",
      "Validation before training Pre-Adapt(-0.884, 0.058)| Inner_loss_B: 0.6283 | Inner_loss_F: 0.1357 | Inner_loss: 6.4190 | NRMSE: 3.6267\n",
      "Validation before training Post-Adapt(-0.884, 0.058)| Inner_loss_B: 0.0121 | Inner_loss_F: 0.1189 | Inner_loss: 0.2399 | NRMSE: 0.1176\n",
      "Validation OOD before training Pre-Adapt(-0.380, 0.911) | Inner_loss_B: 0.6332 | Inner_loss_F: 0.1456 | Inner_loss: 6.4772 | NRMSE: 3.5607\n",
      "Validation OOD before training Post-Adapt(-0.380, 0.911) | Inner_loss_B: 0.0119 | Inner_loss_F: 0.1249 | Inner_loss: 0.2437 | NRMSE: 0.1218\n",
      "Step 140 Pre-Adapt | Inner_loss_B: 0.5322 | Inner_loss_F: 0.1720 | Inner_loss: 5.4935\n",
      "Step 140 Post-Adapt | Inner_loss_B: 0.0025 | Inner_loss_F: 0.1807 | Inner_loss: 0.2055\n",
      "Validation before training Pre-Adapt(-0.884, 0.058)| Inner_loss_B: 0.5456 | Inner_loss_F: 0.1444 | Inner_loss: 5.6003 | NRMSE: 2.4878\n",
      "Validation before training Post-Adapt(-0.884, 0.058)| Inner_loss_B: 0.0025 | Inner_loss_F: 0.1558 | Inner_loss: 0.1807 | NRMSE: 0.0878\n",
      "Validation OOD before training Pre-Adapt(-0.380, 0.911) | Inner_loss_B: 0.5436 | Inner_loss_F: 0.1617 | Inner_loss: 5.5975 | NRMSE: 2.4407\n",
      "Validation OOD before training Post-Adapt(-0.380, 0.911) | Inner_loss_B: 0.0024 | Inner_loss_F: 0.1648 | Inner_loss: 0.1889 | NRMSE: 0.0933\n",
      "Step 160 Pre-Adapt | Inner_loss_B: 0.1747 | Inner_loss_F: 0.1963 | Inner_loss: 1.9429\n",
      "Step 160 Post-Adapt | Inner_loss_B: 0.0014 | Inner_loss_F: 0.1677 | Inner_loss: 0.1813\n",
      "Validation before training Pre-Adapt(-0.884, 0.058)| Inner_loss_B: 0.1773 | Inner_loss_F: 0.1978 | Inner_loss: 1.9711 | NRMSE: 0.5547\n",
      "Validation before training Post-Adapt(-0.884, 0.058)| Inner_loss_B: 0.0015 | Inner_loss_F: 0.1625 | Inner_loss: 0.1775 | NRMSE: 0.0870\n",
      "Validation OOD before training Pre-Adapt(-0.380, 0.911) | Inner_loss_B: 0.1788 | Inner_loss_F: 0.2225 | Inner_loss: 2.0104 | NRMSE: 0.5655\n",
      "Validation OOD before training Post-Adapt(-0.380, 0.911) | Inner_loss_B: 0.0015 | Inner_loss_F: 0.1754 | Inner_loss: 0.1903 | NRMSE: 0.0887\n",
      "Step 180 Pre-Adapt | Inner_loss_B: 0.1368 | Inner_loss_F: 0.2681 | Inner_loss: 1.6362\n",
      "Step 180 Post-Adapt | Inner_loss_B: 0.0017 | Inner_loss_F: 0.1691 | Inner_loss: 0.1859\n",
      "Validation before training Pre-Adapt(-0.884, 0.058)| Inner_loss_B: 0.1449 | Inner_loss_F: 0.2579 | Inner_loss: 1.7067 | NRMSE: 0.4506\n",
      "Validation before training Post-Adapt(-0.884, 0.058)| Inner_loss_B: 0.0019 | Inner_loss_F: 0.1665 | Inner_loss: 0.1856 | NRMSE: 0.0944\n",
      "Validation OOD before training Pre-Adapt(-0.380, 0.911) | Inner_loss_B: 0.1432 | Inner_loss_F: 0.2818 | Inner_loss: 1.7137 | NRMSE: 0.4542\n",
      "Validation OOD before training Post-Adapt(-0.380, 0.911) | Inner_loss_B: 0.0020 | Inner_loss_F: 0.1764 | Inner_loss: 0.1967 | NRMSE: 0.0921\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m maml \u001b[38;5;241m=\u001b[39m MAML(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.0005\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, eqname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoisson\u001b[39m\u001b[38;5;124m'\u001b[39m, zero_shot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, load\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, modelpath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/poisson_zs_2000_ref.data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# maml = MAML(5, 0.01, 0.0001, 10, 2, 100, -1, 1, eqname='burgers', zero_shot=False, load=False, modelpath='models/model_ref/burgers_zs_1000_ref.data')\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# maml = MAML(5, 0.01, 0.0001, 0, 2, 1, low=-1, high=1, eqname='poisson')\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m train_loss, val_loss, val_ood_loss, nrmse, model \u001b[38;5;241m=\u001b[39m \u001b[43mmaml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\pinn-maml-vs-zsl\\maml.py:453\u001b[0m, in \u001b[0;36mMAML.train\u001b[1;34m(self, train_steps, num_train_tasks, num_val_tasks)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    452\u001b[0m train_task \u001b[38;5;241m=\u001b[39m generate_task(num_train_tasks)\n\u001b[1;32m--> 453\u001b[0m inner_loss, inner_loss_b, inner_loss_f, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_outer_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m train_loss[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(inner_loss)\n\u001b[0;32m    456\u001b[0m train_loss[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner_loss_b\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(inner_loss_b)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\pinn-maml-vs-zsl\\maml.py:295\u001b[0m, in \u001b[0;36mMAML._outer_loop\u001b[1;34m(self, task_batch, train)\u001b[0m\n\u001b[0;32m    293\u001b[0m support, query \u001b[38;5;241m=\u001b[39m task\n\u001b[0;32m    294\u001b[0m alpha, beta \u001b[38;5;241m=\u001b[39m query\n\u001b[1;32m--> 295\u001b[0m phi, grad, loss_sup_i, loss_sup_b, loss_sup_f, loss_sup, nrmse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inner_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m inner_loss_b\u001b[38;5;241m.\u001b[39mappend(loss_sup_b)\n\u001b[0;32m    297\u001b[0m inner_loss_f\u001b[38;5;241m.\u001b[39mappend(loss_sup_f)\n",
      "File \u001b[1;32m~\\Documents\\GitHub\\pinn-maml-vs-zsl\\maml.py:146\u001b[0m, in \u001b[0;36mMAML._inner_loop\u001b[1;34m(self, theta, support, train)\u001b[0m\n\u001b[0;32m    142\u001b[0m loss_f \u001b[38;5;241m=\u001b[39m model_phi\u001b[38;5;241m.\u001b[39mcalc_loss_f(input_f, target_f, alpha, beta)\n\u001b[0;32m    144\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_b \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m+\u001b[39m loss_f\n\u001b[1;32m--> 146\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m opt_fn\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    150\u001b[0m inner_loss_b \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [loss_b\u001b[38;5;241m.\u001b[39mitem()]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-1.10.1\\lib\\site-packages\\torch\\_tensor.py:307\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    300\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    301\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    305\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[0;32m    306\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[1;32m--> 307\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-1.10.1\\lib\\site-packages\\torch\\autograd\\__init__.py:154\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    152\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m--> 154\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "maml = MAML(5, 0.01, 0.0005, 0, 2, 1, -1, 1, eqname='poisson', zero_shot=True, load=False, modelpath='models/poisson_zs_2000_ref.data')\n",
    "# maml = MAML(5, 0.01, 0.0001, 10, 2, 100, -1, 1, eqname='burgers', zero_shot=False, load=False, modelpath='models/model_ref/burgers_zs_1000_ref.data')\n",
    "# maml = MAML(5, 0.01, 0.0001, 0, 2, 1, low=-1, high=1, eqname='poisson')\n",
    "\n",
    "train_loss, val_loss, val_ood_loss, nrmse, model = maml.train(1000, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38dedd77-a5f0-47ad-b8e3-61370295503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nrmse_df = pd.DataFrame(nrmse)\n",
    "val_loss_df = pd.DataFrame(val_loss)\n",
    "val_ood_loss_df = pd.DataFrame(val_ood_loss)\n",
    "train_loss_df = pd.DataFrame(train_loss)\n",
    "\n",
    "nrmse_df.to_csv('data/nrmse_poisson_zs_maml.csv')\n",
    "val_loss_df.to_csv('data/val_loss_poisson_zs_maml.csv')\n",
    "val_ood_loss_df.to_csv('data/val_ood_loss_poisson_zs_maml.csv')\n",
    "train_loss_df.to_csv('data/train_loss_zs_maml.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b1537b2-402f-433b-8aaa-01bd59700369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x26798c2e910>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.array(nrmse['nrmse_val_pre_adapt']))\n",
    "plt.plot(np.array(nrmse['nrmse_val']))\n",
    "# plt.plot(np.array(val_loss['inner_loss'])[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69e7cd63-5b8b-482b-bbcb-a762bf08554b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models/poisson_zs_5000_ref.data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m PINN(\u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m5\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, param_num\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, zero_shot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels/poisson_zs_5000_ref.data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-1.10.1\\lib\\site-packages\\torch\\serialization.py:594\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    592\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    596\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    597\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    598\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    599\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-1.10.1\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch-1.10.1\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/poisson_zs_5000_ref.data'"
     ]
    }
   ],
   "source": [
    "model = PINN(20, 5, dim=1, param_num=2, zero_shot=True)\n",
    "model.load_state_dict(torch.load('models/poisson_zs_5000_ref.data'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa6594e-31f3-4c13-a92f-c6842bab8fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Current device:\", device)\n",
    "test_x = np.linspace(-10, 10, num=100).reshape(-1, 1)\n",
    "# test_alpha = np.full((100, 1), alpha[2])\n",
    "# test_beta = np.full((100, 1), beta[2])\n",
    "test_alpha = np.full((100, 1), -0.830)\n",
    "test_beta = np.full((100, 1), -0.617)\n",
    "test_in = np.hstack((test_x, test_alpha, test_beta))\n",
    "test_u = model(torch.Tensor(test_in).to(device))\n",
    "X = test_x\n",
    "\n",
    "Y = np.sin(test_alpha * X) + np.cos(test_beta * X) + 0.1 * X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373331d9-26d3-45e5-9fac-431dbdb93e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = test_u.cpu().detach().numpy()\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X, C, label='PINN')\n",
    "plt.scatter(X, Y, label='Answer')\n",
    "plt.legend()\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc39cc7-4862-4ddb-bfe7-6b128059c634",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt( np.sum((C-Y)**2) / np.sum(C**2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ae952-2dae-49cf-8066-5c8643128e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps = [ 1000 / len(val_loss['inner_loss']) * i for i in range(len(val_loss['inner_loss']))]\n",
    "# idx = [100 * i for i in range(10)]\n",
    "# loss = train_loss['inner_loss_f'][::100]\n",
    "# plt.plot(val_loss['inner_loss'], label='loss')\n",
    "plt.plot(np.mean(nrmse['nrmse_val'], axis=1), label='Val.')\n",
    "plt.plot(np.mean(nrmse['nrmse_val_ood'], axis=1), label='Val. OOD')\n",
    "plt.legend()\n",
    "plt.title('FO-MAML Val. Poisson')\n",
    "# plt.plot( loss)\n",
    "# plt.plot(nrmse['nrmse_val'])\n",
    "# plt.plot(nrmse['nrmse_val_ood'])\n",
    "# plt.plot(train_loss['inner_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf51e6-34c1-46d0-a622-424e88f6f24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a4919f-b3c5-43b2-9405-44497c91636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a42cee-eac9-4394-9421-a89e1effb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_i, loss_b, loss_f, loss, model, val_loss, val_ood_loss, nrmse_set = train(epochs=epochs, lr=lr, i_size=100, b_size=100, f_size=1000, zero_shot=False, load=True, load_data='models/maml_burgers_5000.data', alpha_list=0.01 / np.pi, eqname='burgers')\n",
    "loss_i, loss_b, loss_f, loss, model, val_loss, val_ood_loss, nrmse_set = train(epochs=epochs, lr=lr, i_size=0, b_size=2, f_size=10, zero_shot=False, load=True, load_data='maml.data', alpha_list=0.7, beta_list=-0.9, eqname='poisson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb393f14-2ead-48bf-ac7c-eaac00cacd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_i_2, loss_b_2, loss_f_2, loss_2, model_2, val_loss_2, val_ood_loss_2, nrmse_set_2 = train(epochs=epochs, lr=lr, i_size=100, b_size=100, f_size=1000, zero_shot=False, load=False, load_data='maml.data', alpha_list=0.01 / np.pi, eqname='burgers')\n",
    "loss_i_2, loss_b_2, loss_f_2, loss_2, model_2, val_loss_2, val_ood_loss_2, nrmse_set_2 = train(epochs=epochs, lr=lr, i_size=0, b_size=2, f_size=10, zero_shot=False, load=False, load_data='maml.data', alpha_list=0.7, beta_list=-0.9, eqname='poisson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4677c68e-510c-43ba-9ea9-e0d051fb34ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss Few shot')\n",
    "plt.yscale('log')\n",
    "plt.plot(loss, label='MAML')\n",
    "plt.plot(loss_2, label='Random')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00358e94-f90e-40b0-8bac-1c25ab060bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Relative error Few shot')\n",
    "plt.yscale('log')\n",
    "plt.plot(nrmse_set, label='MAML')\n",
    "plt.plot(nrmse_set_2, label='Random')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1be12f-7744-49cb-8731-5242744665c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Current device:\", device)\n",
    "test_x = np.linspace(-1, 1, num=100).reshape(-1, 1)\n",
    "# test_alpha = np.full((100, 1), alpha[2])\n",
    "# test_beta = np.full((100, 1), beta[2])\n",
    "test_alpha = np.full((100, 1), 0.7)\n",
    "test_beta = np.full((100, 1), 0.7)\n",
    "# test_in = np.hstack((test_x, test_alpha, test_beta))\n",
    "test_u = model_2(torch.Tensor(test_x).to(device))\n",
    "X = test_x\n",
    "\n",
    "Y = np.sin(test_alpha * X) + np.cos(test_beta * X) + 0.1 * X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8998c3ae-9cc2-4f95-a092-1c66c2689387",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = test_u.cpu().detach().numpy()\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(X, C, label='PINN')\n",
    "plt.scatter(X, Y, label='Answer')\n",
    "plt.legend()\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd364c44-e281-468c-b9e9-c1a08a75d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss)\n",
    "plt.plot(loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e5be5d-e097-4cb6-9e0a-c7e2dea80d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from burgers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0e993d-d356-4fb6-9af8-a7b90becfdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtn = 101\n",
    "vxn = 101\n",
    "nu = 0.01 / np.pi\n",
    "vx = np.linspace(-1, 1, vxn)\n",
    "vt = np.linspace(0, 1, vtn)\n",
    "\n",
    "vu = burgers_viscous_time_exact1(nu, vxn, vx, vtn, vt)\n",
    "\n",
    "x, t = np.meshgrid(vx, vt)\n",
    "x = x.reshape(-1, 1)\n",
    "t = t.reshape(-1, 1)\n",
    "\n",
    "plt.scatter(x, t, c=vu, cmap='seismic')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb422fcf-83c4-422c-be16-fa44fa167b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Current device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71300da-7d02-45bc-b01c-e1d59586a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtn = 101\n",
    "vxn = 101\n",
    "nu = 0.01 / np.pi\n",
    "vx = np.linspace(-1, 1, vxn)\n",
    "vt = np.linspace(0, 1, vtn)\n",
    "x, t = np.meshgrid(vx, vt)\n",
    "x = x.reshape(-1, 1)\n",
    "t = t.reshape(-1, 1)\n",
    "alpha = np.full((x.shape), nu)\n",
    "pred = model_2(torch.Tensor(np.hstack((x, t))).to(device)).detach().cpu().numpy()\n",
    "# pred = model(torch.Tensor(np.hstack((x, t))).to(device)).detach().cpu().numpy()\n",
    "truth = burgers_viscous_time_exact1(nu, vxn, vx, vtn, vt).T.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604419bf-42e5-47b5-81b2-1f22d32eeb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, t, c=pred, cmap='seismic')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e57157-de00-457e-8766-698d7506f0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d2c34f-a8b5-4104-9b86-3ca29e33af45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch-1.10.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
